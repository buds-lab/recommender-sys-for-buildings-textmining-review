{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440061b0-f4e4-4452-9bf6-29055ef43b94",
   "metadata": {},
   "source": [
    "### Documentation here https://dev.elsevier.com/documentation/ScienceDirectSearchAPI.wadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafc182-304e-4dd4-9a12-d0dfaa5b1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.elsevier.com/content/search/sciencedirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807638af-e327-4fdb-a606-a553ea555bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ae783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from credentials import keys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80836d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request URL\n",
    "url = 'https://api.elsevier.com/content/search/sciencedirect'\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    \"X-ELS-APIKey\": keys[\"els-apikey\"],  #save the keys in a new python file called credentials.py that has a dict variable called  keys  = {\"key\": \"value\"}\n",
    "    \"X-ELS-Insttoken\": keys[\"els-inst-token\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7dab9-aa30-4316-845e-7e2b33dc012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request URL\n",
    "url = 'https://api.elsevier.com/content/search/sciencedirect'\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    \"X-ELS-APIKey\": keys[\"els-apikey\"],  #save the keys in a new python file called credentials.py that has a dict variable called  keys  = {\"key\": \"value\"}\n",
    "    \"X-ELS-Insttoken\": keys[\"els-inst-token\"],\n",
    "}\n",
    "# Ensure the 'csv' directory exists\n",
    "if not os.path.exists('csv'):\n",
    "    os.makedirs('csv')\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = os.path.join('csv', 'sciencedirect_search_results_indoor_environment_after_2020.csv')\n",
    "\n",
    "# Define the base search query (adjust as needed)\n",
    "#base_query = '((\"recommendation system\" OR \"jitai\" OR \"recommender\" OR \"just-in-time\") AND (\"indoor health\" OR \"indoor environment\") AND (\"built environment\" OR \"building\"))'\n",
    "\n",
    "base_query = 'recommendation system indoor environment'\n",
    "#base_query = '(\"sleep quality\" OR \"stress\" OR \"activity\" OR \"thermal comfort\") AND (\"indoor environment\" OR \"indoor health\")'\n",
    "#base_query = '(\"mobile\" OR \"wearable\" OR \"wearable device\") AND (\"indoor environment\" OR \"indoor health\")'\n",
    "\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['DOI', 'Year', 'Title'])  # Header row\n",
    "\n",
    "    # Iterate over each year from 2000 to 2024\n",
    "    for year in range(2000, 2025):\n",
    "        start = 0  # Start at the beginning for each year\n",
    "        while True:  # Loop to handle pagination for the current year\n",
    "            date_range = f'{year}'  # Set date range to the current year\n",
    "            params = {\n",
    "                'query': base_query,\n",
    "                'date': date_range,\n",
    "                'count': 100,  # Fetch 100 results at a time\n",
    "                'start': start\n",
    "            }\n",
    "\n",
    "            # Send the GET request\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                articles = results['search-results']['entry']\n",
    "                total_fetched = len(articles)\n",
    "\n",
    "                # Write DOI, Year, and Title for each article\n",
    "                for article in articles:\n",
    "                    # Skip articles without a 'dc:identifier'\n",
    "                    if 'dc:identifier' not in article:\n",
    "                        continue\n",
    "                    \n",
    "                    doi = article['dc:identifier'].replace('DOI:', '')\n",
    "                    year = article.get('prism:coverDate', '')[0:4]  # Extract publication year from coverDate\n",
    "                    title = article.get('dc:title', 'Title not available')\n",
    "                    writer.writerow([doi, year, title])\n",
    "                    #writer.writerow([doi, year])\n",
    "\n",
    "                start += total_fetched  # Update `start` for the next page\n",
    "\n",
    "                # Exit loop if there are no more results to fetch for the current year\n",
    "                if total_fetched < 100:\n",
    "                    break\n",
    "            else:\n",
    "                #print(f'Error fetching data for {year}: {response.status_code}')\n",
    "                break  # Exit loop on error\n",
    "\n",
    "print(f'Data has been successfully saved to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87844e-92da-4a8e-a41f-a9a5fea5a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
